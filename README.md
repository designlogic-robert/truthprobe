# TruthProbe v1.2 â€” Reasoning Transparency Layer for LLM Outputs

TruthProbe is a lightweight, portable reasoning-transparency module for LLMs.  
It evaluates any model-generated answer and attaches a **TruthTail** containing:

- Certainty level  
- Evidence strength  
- Bias risk  
- Detected assumptions  
- Topic risk  
- Fact vulnerability  
- Correction flag  

TruthProbe does **not** modify or rewrite the original answer.  
It evaluates only what the model already produced.

---

## ğŸ” Why TruthProbe Exists

LLMs often sound confident even when they're guessing.  
TruthProbe reveals:
- when the model is unsure  
- when assumptions were made  
- when bias could influence the output  
- when the topic is known to be high-risk  
- when the answer may require correction  

This makes AI outputs **auditable, transparent, and safer to use**.

---

## ğŸ§© How TruthProbe Works

TruthProbe runs as a SynCE-compatible runtime mode:

1. The assistant gives its normal answer.  
2. TruthProbe analyzes that answer.  
3. TruthProbe attaches a structured, machine-readable **TruthTail**.  

TruthProbe never adds outside knowledge, only evaluates the answer produced.

---

## ğŸ“¦ Repository Contents
```
truthprobe/
â”œâ”€â”€ README.md
â”œâ”€â”€ truthprobe-mode.laf
â”œâ”€â”€ truthprobe-spec-v1.2.md
â”œâ”€â”€ example-output.md
â””â”€â”€ evaluation/
â”œâ”€â”€ before-after.md
â”œâ”€â”€ comparison-table.md
â”œâ”€â”€ observed-notes.md
â””â”€â”€ calibration-check.md

```
---

## ğŸ“˜ Spec Document

The full public-stable specification is here:

â¡ **truthprobe-spec-v1.2.md**

---

## ğŸ“ Example Output

A full example of TruthProbe applied to a normal LLM response:

â¡ **example-output.md**

---

## ğŸ§ª Evaluation Suite

The `/evaluation/` folder contains:

- before/after comparisons  
- comparison table of behaviors  
- observed behavior notes  
- the full CalibrationCheck program  

Designed so developers can validate TruthProbe behavior in different models.

---

## ğŸ”§ Integration

TruthProbe integrates cleanly into:

- SynCE Runtime (L5)  
- Tooling / prompt engines  
- Evaluation systems  
- Safety/audit workflows  

It requires no external APIs and introduces no hallucination risk.

---

## ğŸ“„ License

MIT.

